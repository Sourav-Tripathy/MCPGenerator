{
  "files": [
    {
      "name": "models.py",
      "content": "from pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Any, Union, Literal\n\n# --- Type Definitions from Plan ---\n\nclass UrlCitation(BaseModel):\n    \"\"\"Details of a URL citation used in the response.\"\"\"\n    title: str = Field(..., description=\"Title of the cited web page.\")\n    exactQuote: str = Field(..., description=\"The exact quote from the source.\")\n    url: str = Field(..., description=\"URL of the source.\")\n    dateTime: str = Field(..., description=\"Timestamp of when the content was accessed or published.\")\n\nclass UrlCitationAnnotation(BaseModel):\n    \"\"\"Annotation indicating a URL citation.\"\"\"\n    type: str = Field(..., description=\"Type of annotation, e.g., 'url_citation'.\")\n    url_citation: UrlCitation = Field(..., description=\"Details of the citation.\")\n\nclass Delta(BaseModel):\n    \"\"\"The change in content for a streaming chunk.\"\"\"\n    content: Optional[str] = Field(None, description=\"The text content delta.\")\n    type: Optional[str] = Field(None, description=\"Type of content, e.g., 'text'.\")\n    annotations: Optional[List[UrlCitationAnnotation]] = Field(None, description=\"List of annotations for the content delta.\")\n\nclass MessageContentItem(BaseModel):\n    \"\"\"Represents a part of the message content, which can be text, an image, or a document.\"\"\"\n    type: Literal['text', 'image_url', 'document_url'] = Field(..., description=\"Type of content ('text', 'image_url', 'document_url')\")\n    text: Optional[str] = Field(None, description=\"Text content. Required if type is 'text'.\")\n    image_url: Optional[Dict[str, str]] = Field(None, description=\"Dictionary containing 'url' key with data URI for image (webp, png, jpeg). Required if type is 'image_url'.\")\n    document_url: Optional[Dict[str, str]] = Field(None, description=\"Dictionary containing 'url' key with data URI for document (txt, pdf). Required if type is 'document_url'.\")\n\n    model_config = {\n        \"extra\": \"forbid\"\n    }\n\nclass Message(BaseModel):\n    \"\"\"Represents a single message in the conversation.\"\"\"\n    role: Literal['user', 'assistant'] = Field(..., description=\"Role of the message sender ('user' or 'assistant').\")\n    content: Union[str, List[MessageContentItem]] = Field(..., description=\"Content of the message. Can be a simple string or a list of content items for multimodal input.\")\n\n    model_config = {\n        \"extra\": \"forbid\"\n    }\n\n# --- Input Model for chat_completion Tool ---\n\nclass DeepSearchChatInput(BaseModel):\n    \"\"\"Input model for the Jina DeepSearch chat completion tool.\"\"\"\n    messages: List[Message] = Field(..., description=\"A list of messages comprising the conversation history.\")\n    model: str = Field(\"jina-deepsearch-v1\", description=\"ID of the model to use. Currently only 'jina-deepsearch-v1' is supported.\")\n    stream: Optional[bool] = Field(True, description=\"Whether to stream back partial progress. Strongly recommended (default: true).\")\n    reasoning_effort: Optional[Literal['low', 'medium', 'high']] = Field(\"medium\", description=\"Constrains effort on reasoning. Default: 'medium'.\")\n    budget_tokens: Optional[int] = Field(None, description=\"Maximum number of tokens allowed. Overrides 'reasoning_effort'.\")\n    max_attempts: Optional[int] = Field(None, description=\"Maximum number of retries. Overrides 'reasoning_effort'.\")\n    no_direct_answer: Optional[bool] = Field(False, description=\"Forces search/thinking steps even for trivial queries. Default: false.\")\n    max_returned_urls: Optional[int] = Field(None, description=\"Maximum number of URLs to include in the final answer.\")\n    structured_output: Optional[Dict[str, Any]] = Field(None, description=\"A JSON schema to ensure the final answer conforms to the specified structure.\")\n    good_domains: Optional[List[str]] = Field(None, description=\"List of domains to prioritize.\")\n    bad_domains: Optional[List[str]] = Field(None, description=\"List of domains to strictly exclude.\")\n    only_domains: Optional[List[str]] = Field(None, description=\"List of domains to exclusively include.\")\n\n    model_config = {\n        \"extra\": \"forbid\" # Forbid extra fields not defined in the model\n    }\n\n# --- Potentially useful for parsing responses, though tool returns Dict[str, Any] ---\n\nclass ChatCompletionChoice(BaseModel):\n    index: int\n    message: Message\n    finish_reason: Optional[str] = None\n\nclass Usage(BaseModel):\n    prompt_tokens: int\n    completion_tokens: int\n    total_tokens: int\n\nclass DeepSearchChatResponse(BaseModel):\n    \"\"\"Represents the structure of a non-streaming response (for reference).\"\"\"\n    id: str\n    object: str\n    created: int\n    model: str\n    choices: List[ChatCompletionChoice]\n    usage: Usage\n    # Potentially other fields like citations, visited_urls etc.\n    # The actual response structure might vary, hence the tool returns Dict[str, Any].\n"
    },
    {
      "name": "api.py",
      "content": "import httpx\nimport logging\nimport os\nimport json\nfrom typing import Dict, Any, AsyncGenerator\n\nfrom models import DeepSearchChatInput\n\nlogger = logging.getLogger(__name__)\n\nclass JinaDeepSearchError(Exception):\n    \"\"\"Custom exception for Jina DeepSearch API errors.\"\"\"\n    def __init__(self, status_code: int, detail: Any):\n        self.status_code = status_code\n        self.detail = detail\n        super().__init__(f\"Jina DeepSearch API Error {status_code}: {detail}\")\n\nclass JinaDeepSearchClient:\n    \"\"\"Client for interacting with the Jina AI DeepSearch API.\"\"\"\n\n    def __init__(self, api_key: Optional[str] = None, timeout: float = 180.0):\n        \"\"\"\n        Initializes the Jina DeepSearch client.\n\n        Args:\n            api_key: The Jina API key. Reads from JINA_API_KEY env var if not provided.\n            timeout: Request timeout in seconds.\n        \"\"\"\n        self.api_key = api_key or os.getenv(\"JINA_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"Jina API key not provided or found in JINA_API_KEY environment variable.\")\n\n        self.base_url = \"https://deepsearch.jina.ai/v1/\"\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\" # Ensure we accept JSON\n        }\n        # Use a longer timeout as DeepSearch can take time, especially non-streaming\n        self.client = httpx.AsyncClient(\n            base_url=self.base_url,\n            headers=self.headers,\n            timeout=timeout\n        )\n\n    async def _request(self, method: str, endpoint: str, payload: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Makes a non-streaming request to the API.\"\"\"\n        try:\n            response = await self.client.request(method, endpoint, json=payload)\n            response.raise_for_status() # Raise HTTPStatusError for 4xx/5xx\n            return response.json()\n        except httpx.HTTPStatusError as e:\n            logger.error(f\"HTTP error calling Jina DeepSearch: {e.response.status_code} - {e.response.text}\")\n            try:\n                detail = e.response.json()\n            except json.JSONDecodeError:\n                detail = e.response.text\n            raise JinaDeepSearchError(status_code=e.response.status_code, detail=detail) from e\n        except httpx.RequestError as e:\n            logger.error(f\"Network error calling Jina DeepSearch: {e}\")\n            raise JinaDeepSearchError(status_code=503, detail=f\"Network error: {e}\") from e\n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to decode JSON response from Jina DeepSearch: {e}\")\n            raise JinaDeepSearchError(status_code=500, detail=f\"Invalid JSON response: {e}\") from e\n\n    async def _stream_request(self, method: str, endpoint: str, payload: Optional[Dict[str, Any]] = None) -> AsyncGenerator[Dict[str, Any], None]:\n        \"\"\"Makes a streaming request to the API and yields parsed SSE events.\"\"\"\n        try:\n            async with self.client.stream(method, endpoint, json=payload) as response:\n                # Check for initial errors before starting to stream\n                if response.status_code >= 400:\n                    error_content = await response.aread()\n                    logger.error(f\"HTTP error calling Jina DeepSearch (stream init): {response.status_code} - {error_content.decode()}\")\n                    try:\n                        detail = json.loads(error_content)\n                    except json.JSONDecodeError:\n                        detail = error_content.decode()\n                    raise JinaDeepSearchError(status_code=response.status_code, detail=detail)\n\n                # Process Server-Sent Events (SSE)\n                buffer = \"\"\n                async for chunk in response.aiter_text():\n                    buffer += chunk\n                    while '\\n\\n' in buffer:\n                        event_str, buffer = buffer.split('\\n\\n', 1)\n                        if event_str.strip():\n                            lines = event_str.strip().split('\\n')\n                            if lines and lines[0].startswith('data: '):\n                                data_json = lines[0][len('data: '):].strip()\n                                if data_json == \"[DONE]\":\n                                    logger.info(\"Stream finished with [DONE] marker.\")\n                                    return # End generation\n                                try:\n                                    data = json.loads(data_json)\n                                    yield data\n                                except json.JSONDecodeError as e:\n                                    logger.warning(f\"Failed to decode stream data chunk: {data_json} - Error: {e}\")\n                            else:\n                                logger.warning(f\"Received unexpected SSE format: {event_str}\")\n                # Process any remaining buffer content if needed (though SSE usually ends with \\n\\n)\n                if buffer.strip():\n                     logger.warning(f\"Trailing data in stream buffer: {buffer}\")\n\n        except httpx.RequestError as e:\n            logger.error(f\"Network error during Jina DeepSearch stream: {e}\")\n            raise JinaDeepSearchError(status_code=503, detail=f\"Network error during stream: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error during Jina DeepSearch stream processing: {e}\", exc_info=True)\n            raise JinaDeepSearchError(status_code=500, detail=f\"Stream processing error: {e}\") from e\n\n    async def chat_completion(self, params: DeepSearchChatInput) -> Dict[str, Any]:\n        \"\"\"\n        Performs a deep search chat completion.\n\n        Handles both streaming and non-streaming requests based on params.stream.\n        If streaming, aggregates the results into a final dictionary matching\n        the expected non-streaming response structure as closely as possible.\n\n        Args:\n            params: The input parameters for the chat completion.\n\n        Returns:\n            A dictionary containing the chat completion result.\n\n        Raises:\n            JinaDeepSearchError: If the API returns an error or network issues occur.\n        \"\"\"\n        endpoint = \"chat/completions\"\n        # Use model_dump to serialize Pydantic model, exclude None values\n        payload = params.model_dump(exclude_none=True)\n        logger.info(f\"Sending request to Jina DeepSearch: {endpoint} with stream={params.stream}\")\n        # logger.debug(f\"Payload: {payload}\") # Be careful logging potentially sensitive message content\n\n        if not params.stream:\n            # Non-streaming request\n            try:\n                result = await self._request(\"POST\", endpoint, payload=payload)\n                logger.info(\"Received non-streaming response from Jina DeepSearch.\")\n                return result\n            except Exception as e:\n                logger.error(f\"Error in non-streaming chat completion: {e}\", exc_info=True)\n                raise # Re-raise the caught JinaDeepSearchError or other exceptions\n        else:\n            # Streaming request - aggregate results\n            final_result = {\n                \"id\": None,\n                \"object\": \"chat.completion\",\n                \"created\": None,\n                \"model\": params.model,\n                \"choices\": [\n                    {\n                        \"index\": 0,\n                        \"message\": {\"role\": \"assistant\", \"content\": \"\"},\n                        \"finish_reason\": None,\n                        # Add potential fields for citations/annotations if needed\n                        \"annotations\": []\n                    }\n                ],\n                \"usage\": None, # Usage is often sent at the end or not at all in streams\n                \"_stream_chunks_processed\": 0 # Internal counter\n            }\n            aggregated_content = \"\"\n            try:\n                async for chunk in self._stream_request(\"POST\", endpoint, payload=payload):\n                    final_result[\"_stream_chunks_processed\"] += 1\n                    # logger.debug(f\"Stream chunk received: {chunk}\")\n                    if not final_result[\"id\"] and chunk.get(\"id\"):\n                        final_result[\"id\"] = chunk.get(\"id\")\n                    if not final_result[\"created\"] and chunk.get(\"created\"):\n                        final_result[\"created\"] = chunk.get(\"created\")\n\n                    if chunk.get(\"choices\"):\n                        delta = chunk[\"choices\"][0].get(\"delta\", {})\n                        if \"content\" in delta and delta[\"content\"] is not None:\n                            aggregated_content += delta[\"content\"]\n                        if chunk[\"choices\"][0].get(\"finish_reason\"):\n                            final_result[\"choices\"][0][\"finish_reason\"] = chunk[\"choices\"][0][\"finish_reason\"]\n                        # Handle annotations if present in delta\n                        if \"annotations\" in delta and delta[\"annotations\"]:\n                             final_result[\"choices\"][0][\"annotations\"].extend(delta[\"annotations\"])\n\n                    # Check for usage information, often sent in the last chunk\n                    if chunk.get(\"usage\"):\n                        final_result[\"usage\"] = chunk[\"usage\"]\n\n                # Update the final aggregated content\n                final_result[\"choices\"][0][\"message\"][\"content\"] = aggregated_content\n\n                if final_result[\"_stream_chunks_processed\"] == 0:\n                    logger.warning(\"Stream completed without receiving any data chunks.\")\n                    # Consider raising an error or returning a specific message\n                    raise JinaDeepSearchError(status_code=500, detail=\"Stream ended prematurely without data.\")\n\n                logger.info(f\"Aggregated streaming response from Jina DeepSearch after {final_result['_stream_chunks_processed']} chunks.\")\n                return final_result\n\n            except Exception as e:\n                logger.error(f\"Error processing streaming chat completion: {e}\", exc_info=True)\n                # Ensure JinaDeepSearchError is raised for consistency\n                if not isinstance(e, JinaDeepSearchError):\n                    raise JinaDeepSearchError(status_code=500, detail=f\"Stream processing failed: {e}\") from e\n                else:\n                    raise # Re-raise the original JinaDeepSearchError\n\n    async def close(self):\n        \"\"\"Closes the underlying HTTP client.\"\"\"\n        await self.client.aclose()\n        logger.info(\"Jina DeepSearch client closed.\")\n"
    },
    {
      "name": "main.py",
      "content": "from mcp.server.fastmcp import FastMCP\nfrom typing import Dict, Any\nimport logging\nimport os\nfrom dotenv import load_dotenv\nimport asyncio\n\nfrom models import DeepSearchChatInput\nfrom api import JinaDeepSearchClient, JinaDeepSearchError\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Initialize MCP Server\nmcp = FastMCP(\n    service_name=\"jina_deepsearch\",\n    description=\"Provides access to Jina AI's DeepSearch capability, an AI agent that combines web searching, reading, and reasoning to answer complex questions. Compatible with OpenAI Chat API schema.\"\n)\n\n# Initialize API Client\n# Ensure JINA_API_KEY is set in your environment or .env file\ntry:\n    api_client = JinaDeepSearchClient()\nexcept ValueError as e:\n    logger.error(f\"Failed to initialize JinaDeepSearchClient: {e}\")\n    # Exit or handle appropriately if API key is missing\n    import sys\n    sys.exit(f\"Error: {e}\")\n\n@mcp.tool()\nasync def chat_completion(params: DeepSearchChatInput) -> Dict[str, Any]:\n    \"\"\"\n    Performs a deep search and reasoning process based on a conversation history.\n\n    It iteratively searches the web, reads content, and reasons to find the best\n    answer to the user's query. Supports streaming responses (recommended).\n\n    Args:\n        params: An object containing the parameters for the chat completion,\n                including messages, model, stream preference, and other options.\n\n    Returns:\n        A dictionary containing the chat completion result from Jina DeepSearch.\n        If stream=true (default), this will be the final aggregated response.\n        If an error occurs, returns a dictionary with an 'error' key.\n    \"\"\"\n    logger.info(f\"Received request for chat_completion tool with model: {params.model}, stream: {params.stream}\")\n    try:\n        result = await api_client.chat_completion(params)\n        logger.info(f\"Successfully completed chat_completion for ID: {result.get('id', 'N/A')}\")\n        return result\n    except JinaDeepSearchError as e:\n        logger.error(f\"Jina API error in chat_completion: {e.status_code} - {e.detail}\")\n        # Return a structured error that MCP can understand\n        return {\n            \"error\": {\n                \"type\": \"api_error\",\n                \"status_code\": e.status_code,\n                \"message\": str(e.detail) if isinstance(e.detail, (str, dict)) else repr(e.detail),\n                \"source\": \"jina_deepsearch\"\n            }\n        }\n    except Exception as e:\n        logger.exception(\"Unexpected error in chat_completion tool\")\n        return {\n            \"error\": {\n                \"type\": \"unexpected_error\",\n                \"message\": str(e),\n                \"source\": \"mcp_server\"\n            }\n        }\n\n# Graceful shutdown\n@mcp.on_event(\"shutdown\")\nasync def shutdown_event():\n    logger.info(\"Shutting down Jina DeepSearch client...\")\n    await api_client.close()\n    logger.info(\"Client closed. MCP server shutting down.\")\n\nif __name__ == \"__main__\":\n    # Example of how to run the server (adjust host/port as needed)\n    # uvicorn main:mcp --host 0.0.0.0 --port 8000\n    # This basic run() is for simple local testing:\n    # mcp.run() # This might use default ASGI server settings\n\n    # For production, use a proper ASGI server like uvicorn or hypercorn\n    import uvicorn\n    port = int(os.getenv(\"PORT\", 8000))\n    host = os.getenv(\"HOST\", \"127.0.0.1\")\n    logger.info(f\"Starting Jina DeepSearch MCP server on {host}:{port}\")\n    uvicorn.run(mcp, host=host, port=port)\n"
    },
    {
      "name": "requirements.txt",
      "content": "mcp>=0.1.0\nfastmcp>=0.1.0\nhttpx>=0.25.0\npydantic>=2.0.0\npython-dotenv>=1.0.0\nuvicorn>=0.15.0 # Added for running the server\n"
    },
    {
      "name": ".env.example",
      "content": "# Jina AI API Key\n# Obtain your key from Jina AI platform\nJINA_API_KEY=your_jina_api_key_here\n\n# Optional: Server host and port\n# HOST=0.0.0.0\n# PORT=8000\n"
    },
    {
      "name": "README.md",
      "content": "# Jina AI DeepSearch MCP Server\n\nThis project provides a Model Context Protocol (MCP) server implementation for interacting with the [Jina AI DeepSearch API](https://jina.ai/deepsearch/). DeepSearch is an AI agent that combines web searching, reading, and reasoning to answer complex questions requiring up-to-date information or iterative investigation.\n\nThis server uses [FastMCP](https://github.com/datasette/fastmcp) (assuming this is the intended library, adjust if different) to expose the DeepSearch functionality as standardized tools.\n\n## Features\n\n*   Provides an MCP interface to Jina DeepSearch's chat completions endpoint.\n*   Supports multimodal inputs (text, images, documents via data URIs).\n*   Handles both streaming and non-streaming responses.\n*   Configurable reasoning effort, token budget, domain filtering, and more.\n*   Uses Pydantic for robust data validation.\n*   Includes asynchronous API client using `httpx`.\n*   Proper error handling and logging.\n\n## Setup\n\n1.  **Clone the repository (or create the files):**\n    ```bash\n    # If cloned from git\n    # git clone <repository_url>\n    # cd <repository_directory>\n    ```\n\n2.  **Create a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n4.  **Configure Environment Variables:**\n    *   Copy the example environment file:\n        ```bash\n        cp .env.example .env\n        ```\n    *   Edit the `.env` file and add your Jina AI API key:\n        ```dotenv\n        JINA_API_KEY=your_jina_api_key_here\n        ```\n        You can obtain an API key from the [Jina AI platform](https://jina.ai/).\n    *   You can also optionally set `HOST` and `PORT` in the `.env` file.\n\n## Running the Server\n\nYou can run the MCP server using an ASGI server like Uvicorn:\n\n```bash\nuvicorn main:mcp --host 127.0.0.1 --port 8000 --reload\n```\n\n*   `--host`: The interface to bind to (e.g., `127.0.0.1` for local access, `0.0.0.0` for network access).\n*   `--port`: The port to listen on.\n*   `--reload`: Automatically restart the server when code changes (useful for development).\n\nThe server will start, and you can interact with it using an MCP client.\n\n## Available Tools\n\n### `chat_completion`\n\nPerforms a deep search and reasoning process based on a conversation history.\n\n**Input:** `DeepSearchChatInput` model (see `models.py`)\n\n*   `messages` (List[Message], required): Conversation history. Each message has a `role` ('user' or 'assistant') and `content` (string or list of `MessageContentItem` for multimodal).\n*   `model` (str, optional, default: \"jina-deepsearch-v1\"): Model ID.\n*   `stream` (bool, optional, default: `True`): Enable streaming. Highly recommended to avoid timeouts.\n*   `reasoning_effort` (str, optional, default: 'medium'): 'low', 'medium', or 'high'.\n*   `budget_tokens` (int, optional): Max tokens, overrides `reasoning_effort`.\n*   `max_attempts` (int, optional): Max retries, overrides `reasoning_effort`.\n*   `no_direct_answer` (bool, optional, default: `False`): Force search/thinking.\n*   `max_returned_urls` (int, optional): Max URLs in the final answer.\n*   `structured_output` (dict, optional): JSON schema for structured output.\n*   `good_domains` (List[str], optional): Prioritized domains.\n*   `bad_domains` (List[str], optional): Excluded domains.\n*   `only_domains` (List[str], optional): Exclusively included domains.\n\n**Output:** `Dict[str, Any]`\n\n*   If `stream=False`, returns the complete JSON response from the API.\n*   If `stream=True`, the server aggregates the streamed chunks and returns a final JSON object mimicking the non-streaming structure, including the full assistant message content, usage (if provided), finish reason, etc.\n*   In case of errors, returns a dictionary with an `\"error\"` key containing details.\n\n## Authentication\n\nThe server uses Bearer token authentication. The API key provided in the `.env` file (`JINA_API_KEY`) is automatically included in the `Authorization` header for requests to the Jina DeepSearch API.\n\n## Rate Limits\n\nThe Jina DeepSearch API has rate limits (e.g., 10 requests per minute as per the plan). This MCP server implementation does *not* include client-side rate limiting. Ensure your usage patterns comply with Jina AI's limits.\n\n## Error Handling\n\nThe server catches errors from the `httpx` client (network issues, timeouts) and HTTP status errors from the Jina API (e.g., 4xx, 5xx). It logs errors and returns a structured JSON error response to the MCP client.\n\n## Example Usage (Conceptual MCP Client)\n\n```python\nimport asyncio\nfrom mcp.client.aio import AsyncMCPClient\n\nasync def main():\n    client = AsyncMCPClient(\"http://127.0.0.1:8000\") # URL of your running MCP server\n\n    try:\n        response = await client.jina_deepsearch.chat_completion(\n            params={\n                \"messages\": [\n                    {\"role\": \"user\", \"content\": \"What were the key announcements from Apple's latest WWDC?\"}\n                ],\n                \"stream\": True, # Recommended\n                \"reasoning_effort\": \"medium\"\n            }\n        )\n\n        if \"error\" in response:\n            print(f\"Error: {response['error']}\")\n        else:\n            print(\"DeepSearch Response:\")\n            # Process the successful response dictionary\n            print(response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\"))\n            print(\"--- Usage ---\")\n            print(response.get(\"usage\"))\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        await client.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n"
    }
  ]
}