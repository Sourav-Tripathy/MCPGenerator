from typing import List, Optional, Dict, Any, Literal
from pydantic import BaseModel, Field

# --- Basic Types defined in Implementation Plan ---

class ChatMessage(BaseModel):
    """Represents a single message in the conversation."""
    role: Literal['user', 'assistant', 'system'] = Field(..., description="The role of the message author ('user', 'assistant', or 'system').")
    content: Any = Field(..., description="The content of the message. Typically string, but can be complex for multimodal inputs (e.g., data URI for images/files).")

class UrlCitation(BaseModel):
    """Details about a URL citation used in the response."""
    title: Optional[str] = Field(None, description="Title of the cited web page.")
    exactQuote: Optional[str] = Field(None, description="The exact quote from the source.")
    url: str = Field(..., description="The URL of the citation.")
    dateTime: Optional[str] = Field(None, description="Timestamp associated with the citation.")

class Annotation(BaseModel):
    """Annotation within the response content, like a URL citation."""
    type: str = Field(..., description="Type of annotation (e.g., 'url_citation').")
    url_citation: Optional[UrlCitation] = Field(None, description="Details if the annotation is a URL citation.")

class Delta(BaseModel):
    """The content delta in a streaming chunk."""
    role: Optional[Literal['assistant']] = Field(None, description="The role of the author of this message.")
    content: Optional[str] = Field(None, description="The contents of the chunk message.")
    type: Optional[str] = Field(None, description="Type of content (e.g., 'text').") # Note: Added based on typical OpenAI schema

# --- Input Model for the Tool ---

class DeepSearchChatParams(BaseModel):
    """Input parameters for the DeepSearch chat_completion tool."""
    messages: List[ChatMessage] = Field(..., description="A list of messages comprising the conversation history.")
    model: str = Field("jina-deepsearch-v1", description="ID of the model to use.")
    stream: bool = Field(True, description="Whether to stream the response using Server-Sent Events. Strongly recommended.")
    reasoning_effort: Optional[Literal['low', 'medium', 'high']] = Field("medium", description="Constrains effort on reasoning.")
    budget_tokens: Optional[int] = Field(None, description="Maximum number of tokens allowed for the DeepSearch process.")
    max_attempts: Optional[int] = Field(None, description="Maximum number of retries for solving the problem.")
    no_direct_answer: Optional[bool] = Field(False, description="Forces further thinking/search steps.")
    max_returned_urls: Optional[int] = Field(None, description="Maximum number of relevant URLs to include.")
    structured_output: Optional[Dict[str, Any]] = Field(None, description="A JSON schema to ensure the final answer matches the specified structure.")
    good_domains: Optional[List[str]] = Field(None, description="List of domains to prioritize.")
    bad_domains: Optional[List[str]] = Field(None, description="List of domains to strictly exclude.")
    only_domains: Optional[List[str]] = Field(None, description="List of domains to exclusively include.")

    class Config:
        # Ensure that default values are used even if None is passed explicitly for optional fields
        # Pydantic v2 behavior might handle this better, but being explicit can help
        validate_assignment = True

# --- Output Models (Mirroring OpenAI Schema + DeepSearch specifics) ---

class DeepSearchUsage(BaseModel):
    """Token usage statistics for the request."""
    prompt_tokens: int = Field(..., description="Number of tokens in the prompt.")
    completion_tokens: int = Field(..., description="Number of tokens in the generated completion.")
    total_tokens: int = Field(..., description="Total number of tokens used in the request.")

class DeepSearchChoice(BaseModel):
    """A single choice generated by the model (non-streaming)."""
    index: int = Field(..., description="The index of the choice in the list of choices.")
    message: ChatMessage = Field(..., description="A chat completion message generated by the model.")
    finish_reason: Optional[str] = Field(None, description="The reason the model stopped generating tokens.")
    # DeepSearch specific additions might appear here, potentially in message.content or metadata
    annotations: Optional[List[Annotation]] = Field(None, description="Annotations related to the message content, like citations.")

class DeepSearchChatResponse(BaseModel):
    """The full response object for a non-streaming chat completion request."""
    id: str = Field(..., description="A unique identifier for the chat completion.")
    object: str = Field(..., description="The object type, typically 'chat.completion'.")
    created: int = Field(..., description="The Unix timestamp (in seconds) of when the chat completion was created.")
    model: str = Field(..., description="The model used for the chat completion.")
    choices: List[DeepSearchChoice] = Field(..., description="A list of chat completion choices.")
    usage: Optional[DeepSearchUsage] = Field(None, description="Usage statistics for the completion request.")
    # DeepSearch specific additions
    visited_urls: Optional[List[UrlCitation]] = Field(None, description="List of URLs visited during the search process.")

class DeepSearchStreamChoice(BaseModel):
    """A single choice delta in a streaming response."""
    index: int = Field(..., description="The index of the choice in the list of choices.")
    delta: Delta = Field(..., description="A chat completion delta generated by the model.")
    finish_reason: Optional[str] = Field(None, description="The reason the model stopped generating tokens. Sent in the final chunk.")
    # DeepSearch specific additions might appear here
    annotations: Optional[List[Annotation]] = Field(None, description="Annotations related to the message content, like citations. May appear in chunks.")

class DeepSearchChatChunk(BaseModel):
    """A chunk of data received during a streaming chat completion request."""
    id: str = Field(..., description="A unique identifier for the chat completion. Each chunk has the same ID.")
    object: str = Field(..., description="The object type, typically 'chat.completion.chunk'.")
    created: int = Field(..., description="The Unix timestamp (in seconds) of when the chunk was created.")
    model: str = Field(..., description="The model used for the chat completion.")
    choices: List[DeepSearchStreamChoice] = Field(..., description="A list of chat completion choices. Can contain more than one choice if n > 1.")
    usage: Optional[DeepSearchUsage] = Field(None, description="Usage statistics. Often sent in the final chunk.")
    # DeepSearch specific additions
    visited_urls: Optional[List[UrlCitation]] = Field(None, description="List of URLs visited. May appear in the final chunk.")

# --- Error Model ---

class MCPErrorResponse(BaseModel):
    """Standard error response format for MCP tools."""
    error: str = Field(..., description="Description of the error that occurred.")
