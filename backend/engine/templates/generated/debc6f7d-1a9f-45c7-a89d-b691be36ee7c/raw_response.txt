{
  "files": [
    {
      "name": "models.py",
      "content": "from pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Any, Literal, Union\n\n# --- Type Definitions from Plan ---\n\nclass ChatMessage(BaseModel):\n    \"\"\"Represents a single message in the conversation.\"\"\"\n    role: Literal['user', 'assistant', 'system'] = Field(..., description=\"The role of the message author.\")\n    content: Union[str, List[Dict[str, Any]]] = Field(..., description=\"The content of the message. Can be text or a list for multimodal inputs (e.g., text and image URLs or data URIs).\")\n\nclass URLCitation(BaseModel):\n    \"\"\"Details of a URL citation within the response.\"\"\"\n    title: Optional[str] = Field(None, description=\"Title of the cited web page.\")\n    exactQuote: Optional[str] = Field(None, alias=\"exactQuote\", description=\"The exact quote from the source.\")\n    url: str = Field(..., description=\"URL of the source.\")\n    dateTime: Optional[str] = Field(None, alias=\"dateTime\", description=\"Timestamp associated with the citation.\")\n\nclass Annotation(BaseModel):\n    \"\"\"Annotation associated with the content, like a citation.\"\"\"\n    type: str = Field(..., description=\"Type of annotation (e.g., 'url_citation').\")\n    url_citation: Optional[URLCitation] = Field(None, description=\"Details if the annotation is a URL citation.\")\n\nclass ChoiceDelta(BaseModel):\n    \"\"\"The delta content for a streaming choice.\"\"\"\n    role: Optional[Literal['assistant']] = Field(None, description=\"Role of the author ('assistant').\")\n    content: Optional[str] = Field(None, description=\"The text content delta.\")\n    type: Optional[str] = Field(None, description=\"Type of content (e.g., 'text').\")\n    annotations: Optional[List[Annotation]] = Field(None, description=\"Annotations related to the content delta.\")\n\nclass ResponseMessage(BaseModel):\n    \"\"\"The complete message content for a non-streaming choice.\"\"\"\n    role: str = Field(..., description=\"Role of the author ('assistant').\")\n    content: Optional[str] = Field(None, description=\"The full text content.\")\n    type: Optional[str] = Field(None, description=\"Type of content (e.g., 'text').\")\n    annotations: Optional[List[Annotation]] = Field(None, description=\"Annotations related to the content.\")\n\n# --- Input Model ---\n\nclass DeepSearchChatInput(BaseModel):\n    \"\"\"Input model for the Jina DeepSearch chat completion tool.\"\"\"\n    messages: List[ChatMessage] = Field(..., description=\"A list of messages comprising the conversation history.\")\n    model: str = Field(\"jina-deepsearch-v1\", description=\"ID of the model to use.\")\n    stream: bool = Field(True, description=\"Whether to stream back partial progress using server-sent events. Recommended to keep enabled to avoid timeouts.\")\n    reasoning_effort: Optional[Literal['low', 'medium', 'high']] = Field(\"medium\", description=\"Constrains effort on reasoning. 'low', 'medium', or 'high'. Lower effort can be faster and use fewer tokens.\")\n    budget_tokens: Optional[int] = Field(None, description=\"Maximum number of tokens allowed for the DeepSearch process. Overrides reasoning_effort.\")\n    max_attempts: Optional[int] = Field(None, description=\"Maximum number of retries for solving the problem. Allows different reasoning approaches. Overrides reasoning_effort.\")\n    no_direct_answer: Optional[bool] = Field(False, description=\"Forces the model to take further thinking/search steps even for seemingly trivial queries.\")\n    max_returned_urls: Optional[int] = Field(None, description=\"Maximum number of URLs to include in the final answer/chunk, sorted by relevance.\")\n    structured_output: Optional[Dict[str, Any]] = Field(None, description=\"JSON schema to ensure the final answer matches the structure.\")\n    good_domains: Optional[List[str]] = Field(None, description=\"List of domains to prioritize for content retrieval.\")\n    bad_domains: Optional[List[str]] = Field(None, description=\"List of domains to strictly exclude from content retrieval.\")\n    only_domains: Optional[List[str]] = Field(None, description=\"List of domains to exclusively include in content retrieval.\")\n\n    class Config:\n        # Ensure Pydantic uses the field names, not aliases, for serialization\n        by_alias = False\n\n# --- Output Models (Inferred from OpenAI Schema & Plan) ---\n\nclass Usage(BaseModel):\n    \"\"\"Token usage statistics.\"\"\"\n    prompt_tokens: Optional[int] = Field(None)\n    completion_tokens: Optional[int] = Field(None)\n    total_tokens: Optional[int] = Field(None)\n\nclass VisitedUrl(BaseModel):\n    \"\"\"Details of a URL visited during the search process.\"\"\"\n    url: str\n    title: Optional[str] = None\n    # Add other fields if the API provides them\n\nclass DeepSearchChunkChoice(BaseModel):\n    \"\"\"A single choice within a streaming chunk.\"\"\"\n    index: int\n    delta: ChoiceDelta\n    finish_reason: Optional[str] = None\n    # Jina specific fields might appear here\n    visited_urls: Optional[List[VisitedUrl]] = Field(None, description=\"URLs visited during the search process, often included in the final chunk.\")\n\nclass DeepSearchChunk(BaseModel):\n    \"\"\"Represents a chunk of data received during streaming.\"\"\"\n    id: str\n    object: str # e.g., 'chat.completion.chunk'\n    created: int\n    model: str\n    choices: List[DeepSearchChunkChoice]\n    usage: Optional[Usage] = Field(None, description=\"Usage statistics, often included in the final chunk.\")\n    # Jina specific fields might appear here\n    search_summary: Optional[Dict[str, Any]] = Field(None, description=\"Summary information about the search process, often in the final chunk.\")\n\nclass DeepSearchResponseChoice(BaseModel):\n    \"\"\"A single choice in a non-streaming response.\"\"\"\n    index: int\n    message: ResponseMessage\n    finish_reason: Optional[str] = None\n    # Jina specific fields might appear here\n    visited_urls: Optional[List[VisitedUrl]] = Field(None, description=\"URLs visited during the search process.\")\n\nclass DeepSearchResponse(BaseModel):\n    \"\"\"Represents the complete response for a non-streaming request.\"\"\"\n    id: str\n    object: str # e.g., 'chat.completion'\n    created: int\n    model: str\n    choices: List[DeepSearchResponseChoice]\n    usage: Optional[Usage] = None\n    # Jina specific fields might appear here\n    search_summary: Optional[Dict[str, Any]] = Field(None, description=\"Summary information about the search process.\")\n"
    },
    {
      "name": "api.py",
      "content": "import httpx\nimport os\nimport logging\nimport json\nfrom typing import AsyncIterator, Union, Optional\nfrom pydantic import ValidationError\n\nfrom models import DeepSearchChatInput, DeepSearchChunk, DeepSearchResponse\n\nlogger = logging.getLogger(__name__) \n\n# Custom Exception for API specific errors\nclass JinaAPIError(Exception):\n    def __init__(self, status_code: int, error_info: dict):\n        self.status_code = status_code\n        self.error_info = error_info\n        super().__init__(f\"Jina API Error {status_code}: {error_info}\")\n\nclass JinaAuthenticationError(JinaAPIError):\n    def __init__(self, error_info: dict):\n        super().__init__(401, error_info)\n\nclass JinaDeepSearchClient:\n    \"\"\"Asynchronous client for interacting with the Jina DeepSearch API.\"\"\"\n\n    DEFAULT_BASE_URL = \"https://deepsearch.jina.ai/v1\"\n    DEFAULT_TIMEOUT = 180.0  # seconds, increased for potentially long searches\n\n    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, timeout: float = DEFAULT_TIMEOUT):\n        self.api_key = api_key or os.getenv(\"JINA_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"JINA_API_KEY environment variable not set.\")\n\n        self.base_url = base_url or self.DEFAULT_BASE_URL\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\" # Ensure JSON responses are requested\n        }\n        self.client = httpx.AsyncClient(\n            base_url=self.base_url,\n            headers=self.headers,\n            timeout=timeout\n        )\n\n    async def close(self):\n        \"\"\"Closes the underlying HTTPX client.\"\"\"\n        await self.client.aclose()\n\n    async def _parse_sse_event(self, line: str) -> Optional[DeepSearchChunk]:\n        \"\"\"Parses a single Server-Sent Event line.\"\"\"\n        line = line.strip()\n        if not line or line.startswith(\":\"):\n            return None\n        if line.startswith(\"data:\"):\n            data_str = line[len(\"data:\"):].strip()\n            if data_str == \"[DONE]\":\n                logger.info(\"Received [DONE] marker from Jina API stream.\")\n                return None\n            try:\n                data_json = json.loads(data_str)\n                return DeepSearchChunk.model_validate(data_json)\n            except json.JSONDecodeError:\n                logger.error(f\"Failed to decode JSON from SSE data: {data_str!r}\")\n                return None # Or raise an error?\n            except ValidationError as e:\n                logger.error(f\"Failed to validate DeepSearchChunk from SSE data: {data_str!r}\\nError: {e}\")\n                return None # Or raise an error?\n        else:\n            logger.warning(f\"Received unexpected SSE line format: {line!r}\")\n            return None\n\n    async def _stream_chat_completion(self, payload: dict) -> AsyncIterator[DeepSearchChunk]:\n        \"\"\"Handles the streaming chat completion request.\"\"\"\n        endpoint = \"/chat/completions\"\n        try:\n            async with self.client.stream(\"POST\", endpoint, json=payload) as response:\n                # Check for initial errors before starting to stream\n                if response.status_code >= 400:\n                    try:\n                        error_body = await response.aread()\n                        error_info = json.loads(error_body.decode())\n                    except Exception:\n                        error_info = {\"error\": f\"HTTP {response.status_code}\", \"detail\": response.reason_phrase}\n                    \n                    if response.status_code == 401:\n                        raise JinaAuthenticationError(error_info)\n                    else:\n                        raise JinaAPIError(response.status_code, error_info)\n                \n                # Process the stream\n                async for line in response.aiter_lines():\n                    chunk = await self._parse_sse_event(line)\n                    if chunk:\n                        yield chunk\n\n        except httpx.TimeoutException as e:\n            logger.error(f\"Request timed out after {self.client.timeout}s: {e}\")\n            raise TimeoutError(f\"Jina API request timed out: {e}\") from e\n        except httpx.RequestError as e:\n            logger.error(f\"An error occurred while requesting {e.request.url!r}: {e}\")\n            raise ConnectionError(f\"Could not connect to Jina API: {e}\") from e\n        except JinaAPIError: # Re-raise specific API errors\n            raise\n        except Exception as e:\n            logger.exception(f\"An unexpected error occurred during streaming chat completion: {e}\")\n            raise RuntimeError(f\"Unexpected error during streaming: {e}\") from e\n\n    async def _non_stream_chat_completion(self, payload: dict) -> DeepSearchResponse:\n        \"\"\"Handles the non-streaming chat completion request.\"\"\"\n        endpoint = \"/chat/completions\"\n        try:\n            response = await self.client.post(endpoint, json=payload)\n            \n            # Check for HTTP errors\n            if response.status_code >= 400:\n                try:\n                    error_info = response.json()\n                except json.JSONDecodeError:\n                     error_info = {\"error\": f\"HTTP {response.status_code}\", \"detail\": response.reason_phrase}\n                \n                if response.status_code == 401:\n                    raise JinaAuthenticationError(error_info)\n                else:\n                    # Note: Non-streaming requests might hit gateway timeouts (e.g., 504) for long tasks\n                    if response.status_code == 504:\n                         logger.warning(\"Received 504 Gateway Timeout. Consider using stream=True for long tasks.\")\n                    raise JinaAPIError(response.status_code, error_info)\n            \n            # Parse successful response\n            response_data = response.json()\n            return DeepSearchResponse.model_validate(response_data)\n\n        except httpx.TimeoutException as e:\n            logger.error(f\"Request timed out after {self.client.timeout}s: {e}\")\n            raise TimeoutError(f\"Jina API request timed out: {e}. Consider using stream=True.\") from e\n        except httpx.RequestError as e:\n            logger.error(f\"An error occurred while requesting {e.request.url!r}: {e}\")\n            raise ConnectionError(f\"Could not connect to Jina API: {e}\") from e\n        except ValidationError as e:\n            logger.error(f\"Failed to validate DeepSearchResponse: {e}\\nResponse data: {response_data!r}\")\n            raise ValueError(f\"Invalid response structure received from Jina API: {e}\") from e\n        except JinaAPIError: # Re-raise specific API errors\n             raise\n        except Exception as e:\n            logger.exception(f\"An unexpected error occurred during non-streaming chat completion: {e}\")\n            raise RuntimeError(f\"Unexpected error: {e}\") from e\n\n    async def chat_completion(self, params: DeepSearchChatInput) -> Union[AsyncIterator[DeepSearchChunk], DeepSearchResponse]:\n        \"\"\"\n        Performs deep search and reasoning based on conversation history.\n\n        Args:\n            params: The input parameters conforming to DeepSearchChatInput model.\n\n        Returns:\n            If stream=True, an async iterator yielding DeepSearchChunk objects.\n            If stream=False, a single DeepSearchResponse object.\n\n        Raises:\n            JinaAuthenticationError: If the API key is invalid.\n            JinaAPIError: For other API-related errors (4xx, 5xx).\n            TimeoutError: If the request times out.\n            ConnectionError: If there's a network issue connecting to the API.\n            ValueError: If the API response structure is invalid.\n            RuntimeError: For unexpected errors.\n        \"\"\"\n        # Use model_dump to serialize Pydantic model, excluding None values\n        # Use by_alias=False to ensure correct field names are sent\n        payload = params.model_dump(exclude_none=True, by_alias=False)\n        logger.info(f\"Sending request to Jina DeepSearch: stream={params.stream}\")\n        # logger.debug(f\"Payload: {payload}\") # Be careful logging potentially sensitive message content\n\n        if params.stream:\n            return self._stream_chat_completion(payload)\n        else:\n            # Warn about potential timeouts with non-streaming\n            logger.warning(\"Executing non-streaming request. This might time out for complex queries. Consider using stream=True.\")\n            return await self._non_stream_chat_completion(payload)\n"
    },
    {
      "name": "main.py",
      "content": "from mcp.server.fastmcp import FastMCP, ToolContext\nfrom typing import Dict, Any, Optional, List, Union, AsyncIterator\nimport logging\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\n\n# Import models and API client\nfrom models import DeepSearchChatInput, DeepSearchChunk, DeepSearchResponse\nfrom api import JinaDeepSearchClient, JinaAPIError, JinaAuthenticationError\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Initialize MCP Server\nmcp = FastMCP(\n    service_name=\"jina_deepsearch\",\n    description=\"Provides access to the Jina DeepSearch API, an AI service that performs iterative web searching, reading, and reasoning to answer complex questions. It is fully compatible with the OpenAI Chat API schema.\"\n)\n\n# Initialize API Client\n# The client will automatically pick up JINA_API_KEY from the environment\ntry:\n    api_client = JinaDeepSearchClient()\nexcept ValueError as e:\n    logger.error(f\"Failed to initialize JinaDeepSearchClient: {e}\")\n    # Decide if the server should exit or continue without a working client\n    # For now, let it potentially fail at runtime when the tool is called\n    api_client = None \n\n@mcp.tool()\nasync def chat_completion(\n    params: DeepSearchChatInput,\n    context: ToolContext\n) -> Union[AsyncIterator[DeepSearchChunk], DeepSearchResponse]:\n    \"\"\"\n    Performs deep search and reasoning based on a conversation history using Jina DeepSearch.\n    \n    It iteratively searches the web, reads content, and reasons to provide a comprehensive \n    answer, citing sources. Suitable for complex questions requiring up-to-date information \n    or multi-hop reasoning. Supports streaming responses for real-time updates.\n\n    Args:\n        params: Input parameters including messages, model, streaming options, etc.\n        context: The MCP ToolContext.\n\n    Returns:\n        If stream=True, returns an async iterator yielding DeepSearchChunk objects.\n        The final chunk contains usage statistics and visited URLs.\n        If stream=False, returns a single DeepSearchResponse object with the complete \n        answer and metadata (potentially prone to timeouts).\n    \"\"\"\n    if not api_client:\n         logger.error(\"Jina API client is not initialized. Check JINA_API_KEY.\")\n         # You might want to raise a specific MCP error here\n         raise RuntimeError(\"Jina API client failed to initialize.\")\n\n    logger.info(f\"Executing chat_completion tool for request ID: {context.request_id}\")\n    try:\n        result = await api_client.chat_completion(params)\n        # The result is either an AsyncIterator or a DeepSearchResponse object\n        # FastMCP handles both correctly.\n        return result\n    except JinaAuthenticationError as e:\n        logger.error(f\"Authentication failed for Jina API: {e.error_info}\")\n        # Re-raise or return a structured error for the MCP client\n        # For now, re-raising to let FastMCP handle it as a server error\n        raise RuntimeError(f\"Jina API Authentication Error: {e.error_info.get('error', 'Invalid API Key')}\") from e\n    except JinaAPIError as e:\n        logger.error(f\"Jina API returned an error ({e.status_code}): {e.error_info}\")\n        raise RuntimeError(f\"Jina API Error ({e.status_code}): {e.error_info.get('error', 'API request failed')}\") from e\n    except TimeoutError as e:\n        logger.error(f\"Jina API request timed out: {e}\")\n        raise TimeoutError(f\"Jina API request timed out. {e}\") from e\n    except ConnectionError as e:\n        logger.error(f\"Could not connect to Jina API: {e}\")\n        raise ConnectionError(f\"Could not connect to Jina API: {e}\") from e\n    except ValueError as e:\n        logger.error(f\"Data validation error: {e}\")\n        raise ValueError(f\"Data validation error: {e}\") from e # e.g., invalid input or response parsing\n    except Exception as e:\n        logger.exception(f\"An unexpected error occurred in chat_completion tool: {e}\")\n        raise RuntimeError(f\"An unexpected server error occurred: {e}\") from e\n\n# Example of how to gracefully shutdown the client (optional)\n@mcp.on_event(\"shutdown\")\nasync def shutdown_event():\n    if api_client:\n        logger.info(\"Closing Jina API client...\")\n        await api_client.close()\n        logger.info(\"Jina API client closed.\")\n\nif __name__ == \"__main__\":\n    # Run the MCP server using uvicorn (handled by mcp.run())\n    # You can configure host, port, etc. via environment variables \n    # or command-line arguments for 'mcp run'\n    # Example: MCP_HOST=0.0.0.0 MCP_PORT=8000 mcp run main:mcp\n    mcp.run()\n"
    },
    {
      "name": "requirements.txt",
      "content": "# MCP Framework\nfastmcp>=0.1.0\n\n# API Client Dependencies\nhttpx>=0.25.0\n\n# Data Validation\npydantic>=2.0.0\n\n# Environment Variables\npython-dotenv>=1.0.0\n\n# ASGI Server (for running)\nuvicorn>=0.20.0\n"
    },
    {
      "name": ".env.example",
      "content": "# Jina DeepSearch API Key\n# Obtain your key from https://jina.ai/cloud/\nJINA_API_KEY=\"your_jina_api_key_here\"\n\n# Optional: Override Jina API base URL (usually not needed)\n# JINA_API_BASE_URL=\"https://deepsearch.jina.ai/v1\"\n\n# Optional: Override API request timeout (default is 180 seconds)\n# JINA_API_TIMEOUT=180.0\n\n# Optional: MCP Server configuration\n# MCP_HOST=127.0.0.1\n# MCP_PORT=8000\n# MCP_LOG_LEVEL=INFO\n"
    },
    {
      "name": "README.md",
      "content": "# Jina DeepSearch MCP Server\n\nThis repository contains a Model Context Protocol (MCP) server implementation for interacting with the [Jina DeepSearch API](https://jina.ai/deepsearch/).\n\nJina DeepSearch is an AI service designed to answer complex questions by iteratively searching the web, reading content, and reasoning. It provides comprehensive answers with cited sources and is compatible with the OpenAI Chat API schema.\n\nThis MCP server exposes the Jina DeepSearch functionality as a tool, making it easy to integrate into applications using the MCP standard.\n\n## Features\n\n*   Provides a `chat_completion` tool to access Jina DeepSearch.\n*   Supports both streaming (Server-Sent Events) and non-streaming responses.\n*   Handles authentication using a Jina API key.\n*   Includes Pydantic models for request inputs and response outputs.\n*   Configurable via environment variables.\n*   Built with [FastMCP](https://github.com/your-org/fastmcp). <!-- Replace with actual link if available -->\n\n## Setup\n\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd <repository-directory>\n    ```\n\n2.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n3.  **Configure Environment Variables:**\n    Copy the example environment file:\n    ```bash\n    cp .env.example .env\n    ```\n    Edit the `.env` file and add your Jina API key:\n    ```env\n    JINA_API_KEY=\"your_jina_api_key_here\"\n    ```\n    You can obtain an API key from the [Jina AI Cloud](https://jina.ai/cloud/).\n\n## Running the Server\n\nYou can run the MCP server using the `mcp` command-line tool (installed with `fastmcp`):\n\n```bash\nmcp run main:mcp\n```\n\nBy default, it will run on `127.0.0.1:8000`. You can configure the host and port using environment variables (`MCP_HOST`, `MCP_PORT`) or command-line arguments:\n\n```bash\nmcp run main:mcp --host 0.0.0.0 --port 8080\n```\n\n## Tools\n\n### `chat_completion`\n\nPerforms deep search and reasoning based on a conversation history.\n\n**Description:**\nIteratively searches the web, reads content, and reasons to provide a comprehensive answer, citing sources. Suitable for complex questions requiring up-to-date information or multi-hop reasoning. Supports streaming responses for real-time updates.\n\n**Input Parameters (`DeepSearchChatInput`):**\n\n*   `messages` (List[`ChatMessage`], required): A list of messages comprising the conversation history. Each message has `role` ('user', 'assistant', 'system') and `content` (string or list for multimodal).\n*   `model` (str, optional, default: `\"jina-deepsearch-v1\"`): ID of the model to use.\n*   `stream` (bool, optional, default: `True`): Whether to stream back partial progress. Recommended to keep enabled.\n*   `reasoning_effort` (Literal['low', 'medium', 'high'], optional, default: `\"medium\"`): Constrains effort on reasoning.\n*   `budget_tokens` (int, optional): Maximum number of tokens allowed. Overrides `reasoning_effort`.\n*   `max_attempts` (int, optional): Maximum number of retries. Overrides `reasoning_effort`.\n*   `no_direct_answer` (bool, optional, default: `False`): Forces search steps even for trivial queries.\n*   `max_returned_urls` (int, optional): Maximum number of URLs in the final answer.\n*   `structured_output` (Dict[str, Any], optional): JSON schema to enforce on the output.\n*   `good_domains` (List[str], optional): Domains to prioritize.\n*   `bad_domains` (List[str], optional): Domains to exclude.\n*   `only_domains` (List[str], optional): Domains to exclusively include.\n\n**Returns:**\n\n*   **If `stream=True`:** An `AsyncIterator[DeepSearchChunk]` yielding Server-Sent Events data parsed into `DeepSearchChunk` objects. The final chunk typically includes `usage` statistics and `visited_urls`.\n*   **If `stream=False`:** A single `DeepSearchResponse` object containing the complete response, including `choices`, `usage`, and `visited_urls`.\n\n**Example Usage (Conceptual MCP Client):**\n\n```python\nimport mcp\n\nasync def main():\n    client = mcp.Client(\"http://localhost:8000\") # URL of the running MCP server\n\n    # Non-streaming example\n    response = await client.tools.jina_deepsearch.chat_completion(\n        params={\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"What were the key announcements at the latest Apple event?\"}\n            ],\n            \"stream\": False\n        }\n    )\n    print(\"Non-streaming response:\", response)\n\n    # Streaming example\n    async for chunk in await client.tools.jina_deepsearch.chat_completion(\n        params={\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Explain the concept of quantum entanglement simply.\"}\n            ],\n            \"stream\": True,\n            \"reasoning_effort\": \"low\"\n        }\n    ):\n        print(\"Stream chunk:\", chunk)\n\n# Run the example\n# asyncio.run(main())\n```\n\n## Error Handling\n\nThe server attempts to catch common errors:\n\n*   **Authentication Errors:** If `JINA_API_KEY` is invalid or missing.\n*   **API Errors:** Errors returned by the Jina API (e.g., bad requests, server errors).\n*   **Timeouts:** If the API request takes too long (especially for non-streaming requests).\n*   **Connection Errors:** Network issues connecting to the Jina API.\n*   **Validation Errors:** If input data is invalid or the API response doesn't match expected models.\n\nErrors will be logged and generally result in an appropriate error response from the MCP server.\n\n## Authentication\n\nAuthentication is handled via an API key (`JINA_API_KEY`) passed in the `Authorization: Bearer <key>` header to the Jina DeepSearch API. Ensure the `JINA_API_KEY` environment variable is set correctly when running the server.\n"
    }
  ]
}